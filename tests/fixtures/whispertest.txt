Testing OpenAI Whisper on Audio Transcription¶
In this notebook, we will be exploring the capabilities of OpenAI's Whisper Automatic Speech Recognition (ASR) system. Whisper is trained on a large amount of multilingual and multitask supervised data collected from the web. It has been applied to a variety of tasks, including transcription of audio data.

We will be testing three different English language models provided by Whisper, namely:

Small Model
Medium Model
Large Model
Each model will be tested on the same audio file, allowing us to observe the differences in their transcriptions. The objective is to understand the trade-offs between these models in terms of accuracy and resource utilization.

First let's install Whisper
! pip install git+https://github.com/openai/whisper.git -q
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv
Whisper ASR Models: Small, Medium, and Large
These three models represent different trade-offs between transcription accuracy and computational resources. The small model is designed to be lightweight and fast, while the large model is designed to provide the highest transcription accuracy, albeit with greater computational requirements.

import whisper

small_model = whisper.load_model("small")
medium_model = whisper.load_model("medium")
large_model = whisper.load_model("large")
100%|████████████████████████████████████████| 461M/461M [00:02<00:00, 167MiB/s]
100%|█████████████████████████████████████| 1.42G/1.42G [00:37<00:00, 40.2MiB/s]
100%|██████████████████████████████████████| 2.87G/2.87G [00:30<00:00, 102MiB/s]
Audio File for Testing
The audio file used for testing is an extract from the movie "The Dark Knight Rises". This clip contains a notable monologue by the character Bane, providing a good mix of pace, intonation, and background noise for testing the ASR system.

!wget -O audio.mp3 http://www.moviesoundclips.net/movies1/darkknightrises/darkness.mp3
--2023-05-27 01:12:54--  http://www.moviesoundclips.net/movies1/darkknightrises/darkness.mp3
Resolving www.moviesoundclips.net (www.moviesoundclips.net)... 198.54.115.219
Connecting to www.moviesoundclips.net (www.moviesoundclips.net)|198.54.115.219|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 168872 (165K) [audio/mpeg]
Saving to: ‘audio.mp3’

audio.mp3           100%[===================>] 164.91K   623KB/s    in 0.3s    

2023-05-27 01:12:55 (623 KB/s) - ‘audio.mp3’ saved [168872/168872]

from IPython.display import Audio
Audio("audio.mp3")
Original transcription
"Oh, you think darkness is your ally. But you merely adopted the dark. I was born in it, molded by it. I didn't see the light until I was already a man, by then it was nothing to me but blinding!"

Comparing Transcriptions
We will compare the transcriptions generated by each model to the original script, providing a qualitative analysis of their performance. This will help us understand the strengths and weaknesses of each model, and guide the choice of model for different use cases.

small_result = small_model.transcribe('audio.mp3', fp16=False)
print(small_result["text"])
 Oh, you think darkness is your ally? You merely adopted the dark. I was born in it. Molded by it. I didn't see the light until I was already a man, but then it was nothing to me but blinding!
medium_result = medium_model.transcribe("audio.mp3", fp16=False)
print(medium_result["text"])
 Oh, you think darkness is your ally? You merely adopted the dark. I was born in it. Molded by it. I didn't see the light until I was already a man. By then it was nothing to me but BLINDIN'.
large_result = large_model.transcribe("audio.mp3", fp16=False)
print(large_result["text"])
 Oh, you think darkness is your ally. You merely adopted the dark. I was born in it, molded by it. I didn't see the light until I was already a man. By then it was nothing to me but blight.